{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from src.config import PRICE_FILE  # path to prices.parquet\n",
    "\n",
    "# ⬇️  tell pandas not to truncate anything\n",
    "pd.set_option(\"display.max_rows\",    None)   # show all rows\n",
    "pd.set_option(\"display.max_columns\", None)   # show all columns\n",
    "pd.set_option(\"display.width\",       None)   # don't wrap long lines\n",
    "pd.set_option(\"display.max_colwidth\", None)  # don't truncate column names\n",
    "\n",
    "df = pd.read_parquet(PRICE_FILE)\n",
    "\n",
    "df    # or display(df) – will now render the entire table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1  : 14.9 %\n",
      "Top-10  : 54.9 %\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "gt  = pd.read_csv(\"data/PROXY_MATCHES_TRAINING_DATA(in).csv\")[[\"target\", \"proxy\"]]\n",
    "res = pd.read_csv(\"data/match_top10.csv\")\n",
    "k = 10  # number of top proxies to consider\n",
    "merged = gt.merge(res, on=\"target\", how=\"left\")\n",
    "top1  = (merged[\"proxy\"] == merged[\"proxy1\"]).mean()\n",
    "topk  = merged.apply(\n",
    "          lambda r: r[\"proxy\"] in [r[f\"proxy{i}\"] for i in range(1,11)], axis=1\n",
    "        ).mean()\n",
    "print(\"Top-1  :\", round(top1*100, 1), \"%\")\n",
    "print(\"Top-10  :\", round(topk*100, 1), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth rows   : 270\n",
      "Predictions rows    : 354\n",
      "\n",
      "Top-1 accuracy      : 51/270  (18.9%)\n",
      "Top-10 accuracy     : 123/270  (45.6%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ── 1. load & clean ground-truth table ─────────────────────────────\n",
    "gt = (\n",
    "    pd.read_csv(\"data/PROXY_MATCHES_TRAINING_DATA(in).csv\")[[\"target\", \"proxy\"]]\n",
    "      .dropna()                                   # drop blank rows\n",
    "      .drop_duplicates(subset=\"target\")           # keep one row per target\n",
    "      .assign(proxy=lambda d: d[\"proxy\"].str.strip().str.upper())\n",
    ")\n",
    "\n",
    "# ── 2. load & clean predictions (proxy1 … proxy10) ─────────────────\n",
    "res = pd.read_csv(\"data/match_top10.csv\")\n",
    "for i in range(1, 11):\n",
    "    res[f\"proxy{i}\"] = res[f\"proxy{i}\"].str.strip().str.upper()\n",
    "\n",
    "# ── 3. align by target & evaluate ─────────────────────────────────\n",
    "merged = gt.merge(res, on=\"target\", how=\"left\")\n",
    "\n",
    "top1_hits = merged[\"proxy\"] == merged[\"proxy1\"]\n",
    "top1_num  = top1_hits.sum()\n",
    "top1_den  = len(gt)\n",
    "\n",
    "top10_hits = merged.apply(\n",
    "    lambda r: r[\"proxy\"] in [r.get(f\"proxy{i}\") for i in range(1, 11)], axis=1\n",
    ")\n",
    "top10_num = top10_hits.sum()\n",
    "top10_den = len(gt)\n",
    "\n",
    "# ── 4. print results ──────────────────────────────────────────────\n",
    "print(f\"Ground-truth rows   : {top1_den}\")\n",
    "print(f\"Predictions rows    : {len(res)}\\n\")\n",
    "\n",
    "print(f\"Top-1 accuracy      : {top1_num}/{top1_den}  ({top1_num/top1_den:.1%})\")\n",
    "print(f\"Top-10 accuracy     : {top10_num}/{top10_den}  ({top10_num/top10_den:.1%})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth rows   : 270\n",
      "Predictions rows    : 354\n",
      "\n",
      "Top-1 accuracy      : 50/270  (18.5%)\n",
      "Top-500 accuracy     : 120/270  (44.4%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ── 1. load & clean ground-truth table ─────────────────────────────\n",
    "gt = (\n",
    "    pd.read_csv(\"data/PROXY_MATCHES_TRAINING_DATA(in).csv\")[[\"target\", \"proxy\"]]\n",
    "      .dropna()                                   # drop blank rows\n",
    "      .drop_duplicates(subset=\"target\")           # keep one row per target\n",
    "      .assign(proxy=lambda d: d[\"proxy\"].str.strip().str.upper())\n",
    ")\n",
    "\n",
    "# ── 2. load & clean predictions (proxy1 … proxy10) ─────────────────\n",
    "res = pd.read_csv(\"data/match_top500.csv\")\n",
    "for i in range(1, 501):\n",
    "    res[f\"proxy{i}\"] = res[f\"proxy{i}\"].str.strip().str.upper()\n",
    "\n",
    "\n",
    "# ── 3. align by target & evaluate ─────────────────────────────────\n",
    "merged = gt.merge(res, on=\"target\", how=\"left\")\n",
    "\n",
    "top1_hits = merged[\"proxy\"] == merged[\"proxy1\"]\n",
    "top1_num  = top1_hits.sum()\n",
    "top1_den  = len(gt)\n",
    "\n",
    "top100_hits = merged.apply(\n",
    "    lambda r: r[\"proxy\"] in [r.get(f\"proxy{i}\") for i in range(1, 11)], axis=1\n",
    ")\n",
    "top100_num = top100_hits.sum()\n",
    "top100_den = len(gt)\n",
    "\n",
    "# ── 4. print results ──────────────────────────────────────────────\n",
    "print(f\"Ground-truth rows   : {top1_den}\")\n",
    "print(f\"Predictions rows    : {len(res)}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Top-1 accuracy      : {top1_num}/{top1_den}  ({top1_num/top1_den:.1%})\")\n",
    "print(f\"Top-500 accuracy     : {top100_num}/{top100_den}  ({top100_num/top100_den:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bucket\n",
      "OK, should count hit    259\n",
      "A  (filtered)            11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, json, duckdb, numpy as np\n",
    "\n",
    "truth  = pd.read_csv(\"data/PROXY_MATCHES_TRAINING_DATA(in).csv\")\n",
    "truth  = truth.dropna(subset=[\"proxy\"]).reset_index(drop=True)\n",
    "\n",
    "matches = pd.read_csv(\"data/match_top500.csv\")          # your latest run\n",
    "proxy_profiles = json.load(open(\"data/profiles/proxy.json\"))\n",
    "\n",
    "# Get price matrix columns once\n",
    "cols = duckdb.sql(\"SELECT * FROM 'data/prices.parquet'\").fetchdf().columns\n",
    "\n",
    "def bucket(row):\n",
    "    target = row[\"target\"]\n",
    "    real   = row[\"proxy\"]          # ground-truth proxy\n",
    "    # ➊ was it in candidate list at all?\n",
    "    cand_cols = [c for c in matches.columns if c.startswith(\"proxy\")]\n",
    "    cand_set  = set(matches.loc[matches.target == target, cand_cols].values.ravel())\n",
    "    if real in cand_set:\n",
    "        if real in cols:\n",
    "            return \"OK, should count hit\"      # sanity\n",
    "        else:\n",
    "            return \"B  (price-NaN)\"\n",
    "    else:\n",
    "        return \"A  (filtered)\"\n",
    "\n",
    "truth[\"bucket\"] = truth.apply(bucket, axis=1)\n",
    "print(truth[\"bucket\"].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
